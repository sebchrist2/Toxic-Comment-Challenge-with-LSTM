{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#import all necessary Libraries\nimport sys, os, re, csv, codecs, numpy as np, pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom keras.models import Sequential\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n\nfrom keras.models import Model\nfrom keras import initializers, regularizers, constraints, optimizers, layers","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"# upload the data set\nsample_submission = pd.read_csv(\"../input/sample_submission.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\ntest_labels = pd.read_csv(\"../input/test_labels.csv\")\ntrain = pd.read_csv(\"../input/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's have a look of our train our train dataset\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from the train and test dataset create input and output \nlist_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n#y represents the different categories of comments \ny = train[list_classes].values\n# The input will be the columns \"comment_text\".\nlist_sentences_train = train[\"comment_text\"]\nlist_sentences_test = test[\"comment_text\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"This class allows to vectorize a text corpus, by turning each text into either a sequence of integers \n(each integer being the index of a token in a dictionary) or into a vector where the coefficient for each token could be binary,\nbased on word count, based on tf-idf... (from https://keras.io)\"\"\"\n\n#max_features the maximum number of words to keep in our dictionnary\nmax_features = 20000\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(list_sentences_train))\nlist_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\nlist_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"as the sentences don't have the same length we set the maximum length of one sentences/comment\n then we  will use pad_sequences which transaforms the list of tokenized sentence into a numpy array,\n \n which will the be used the LSTM Model  \"\"\"\n\nmaxlen = 200\nX_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\nX_te = pad_sequences(list_tokenized_test, maxlen=maxlen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"Now that our data is ready we can create our model and train it. i am going to explain each part of the model\"\"\"\nprint('Build model...')\n#the sequential model is a linear stack of layers. after creating it we use the function add() to add different layers.\nmodel = Sequential()\n# Embedding layer Turns positive integers (indexes) into dense vectors of fixed size\nmodel.add(Embedding(max_features, 128))\n# LSTM is a neural network unlike a feedforward network LSTM has feedback. it performs well on text classification\nmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n\n# Dense layer is just a regular densely connected NN with 6 neurons which corresponds to 6 categories of comments\nmodel.add(Dense(6, activation='sigmoid'))\n\n# let's Compile our model\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nprint('Train...')\n# now that everything is set let's fit the model to the datamodel.fit(X_t, y,\n          batch_size=32,\n          epochs=2,\n          validation_split=0.1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# use the model to predict the output of the test data\ny_test = model.predict(X_te)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a submission file \nsubmission_df = pd.DataFrame(columns=['id'] + list_classes)\nsubmission_df['id'] = test['id'].values \nsubmission_df[list_classes] = y_test \nsubmission_df.to_csv(\"./Prediction_Results.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":1}